{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b993eb",
   "metadata": {},
   "source": [
    "First we need to import used libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31215b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym, itertools, numpy as np, pandas as pd, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c9c90",
   "metadata": {},
   "source": [
    "After that we can divide observation space values into certain ranges (cart position and pole angle are fixed, cart velocity and pole angular velocity need to be calculated by GA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0328da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_observation_to_1D(observation, bits):\n",
    "    rule = []\n",
    "    lst_observations =[]\n",
    "    #var_for_velocity is fixed value for now\n",
    "    var_for_velocity = 5\n",
    "\n",
    "    #given range (-2.4, 2.4)\n",
    "    cart_position_range = np.linspace(-2.4, 2.4, num=bits+1)\n",
    "    lst_observations.append(cart_position_range)\n",
    "    #TODO\n",
    "    cart_velocity_range = np.linspace(-var_for_velocity, var_for_velocity, num=bits+1)\n",
    "    lst_observations.append(cart_velocity_range)\n",
    "    #given range (-0.2095 rad, 0.2095 rad)\n",
    "    pole_angle_range = np.linspace(-0.2095, 0.2095, num=bits+1)\n",
    "    lst_observations.append(pole_angle_range)\n",
    "    #TODO\n",
    "    pole_angular_velocity = np.linspace(-var_for_velocity, var_for_velocity, num=bits+1)\n",
    "    lst_observations.append(pole_angular_velocity)\n",
    "\n",
    "    for observation_index in range(len(lst_observations)):\n",
    "        for index in range(1, len(lst_observations[observation_index])):\n",
    "            #lower bound value <= observed value <= upper bound value\n",
    "            if lst_observations[observation_index][index-1] <= observation[observation_index] <= lst_observations[observation_index][index]:\n",
    "                rule.append(1)\n",
    "                #if we find it then fill the rest with 0s and break loop\n",
    "                for i in range(len(lst_observations[observation_index])-index-1):\n",
    "                    rule.append(0)\n",
    "                break\n",
    "            else:\n",
    "                rule.append(0)\n",
    "                \n",
    "        #5 break cells between observation values\n",
    "        for i in range(0,5):\n",
    "            rule.append(0)\n",
    "            \n",
    "    return rule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ddedc1",
   "metadata": {},
   "source": [
    "Rule as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a95ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rules:\n",
    "    def __init__(self,geno={},fitness=0, num_neighbours=5):\n",
    "        self.geno = geno\n",
    "        self.fitness = fitness\n",
    "        self.num_neighbours = num_neighbours\n",
    "\n",
    "        combinations_n_neighbours = list(itertools.product([0, 1], repeat=num_neighbours))\n",
    "        combinations_n_neighbours = [\"\".join(str(seq)).replace(',','').replace(' ','').replace('(','').replace(')','') for seq in combinations_n_neighbours]\n",
    "\n",
    "        self.configurations = combinations_n_neighbours\n",
    "\n",
    "    def update_geno(self,gene):\n",
    "        \n",
    "        for i in range(len(self.configurations)):\n",
    "            self.geno[self.configurations[i]] = gene[i]\n",
    "\n",
    "\n",
    "    def random_initiation(self):\n",
    "        if self.geno == {}:\n",
    "            _ = {}\n",
    "\n",
    "            for configuration in self.configurations:\n",
    "                _[configuration] = random.choice([0,1])\n",
    "\n",
    "            self.geno = _\n",
    "            return\n",
    "\n",
    "    def update_fitness(self,new_fitness):\n",
    "        self.fitness = new_fitness\n",
    "\n",
    "    def reproduce(self, other, method='random_one_point'):\n",
    "        if method == 'random_one_point':\n",
    "            split_point = random.randrange(len(self.geno.values()))\n",
    "            first_half = list(self.geno.values())[:split_point]\n",
    "            second_half = list(other.geno.values())[split_point:]\n",
    "            _ = first_half + second_half\n",
    "        \n",
    "        child = rules()\n",
    "        child.update_geno(_)\n",
    "        return child   \n",
    "\n",
    "    def mutate(self,p=0.01):\n",
    "        _ = list(self.geno.values())\n",
    "        \n",
    "        _ = [digit if random.random() > p else 1 - digit for digit in _]\n",
    "        \n",
    "        self.update_geno(_)\n",
    "        self.update_fitness(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c68968",
   "metadata": {},
   "source": [
    "Create list containing rulesets which map every combinations of 5 neighbours bits to randomly chosen 0 or 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277bb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ruleset(size):\n",
    "    ruleset = []\n",
    "\n",
    "    for _ in range(0,size):\n",
    "        rule = rules()\n",
    "        rule.random_initiation()\n",
    "        ruleset.append(rule)\n",
    "\n",
    "    return ruleset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8ff03",
   "metadata": {},
   "source": [
    "We define function action to behave accordingly to previously generated ruleset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "032b9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(mapped_observation, rule):\n",
    "    v = 0\n",
    "    oldline = mapped_observation\n",
    "    newline = [0] * len(mapped_observation)\n",
    "    for x in range(0,len(mapped_observation)):\n",
    "        for bit in range(len(oldline)):\n",
    "            combination = str(oldline[bit % 60]) + str(oldline[(bit+1) % 60]) + str(oldline[(bit+2) % 60]) + str(oldline[(bit+3) % 60]) + str(oldline[(bit+4) % 60])\n",
    "            newline[(bit+2) % 60] = rule.geno[combination]\n",
    "        oldline = newline\n",
    "\n",
    "    v = 1 if newline.count(1) > (len(mapped_observation)/2) else 0\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880bdfd",
   "metadata": {},
   "source": [
    "Selecting candidates for reproduction or mutation using fitness proportionate selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefd2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one(ruleset):\n",
    "    total_fitness =  sum([rule.fitness for rule in ruleset])\n",
    "    selection_probs = [rule.fitness/total_fitness for rule in ruleset]\n",
    "    return np.random.choice(ruleset, p=selection_probs)\n",
    "\n",
    "def select_parents(ruleset):\n",
    "    total_fitness =  sum([rule.fitness for rule in ruleset])\n",
    "    selection_probs = [rule.fitness/total_fitness for rule in ruleset]\n",
    "    return np.random.choice(ruleset, size=2, replace=False, p=selection_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83efbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evovle(ruleset, p_n, p_crossover):\n",
    "    m = len(ruleset)\n",
    "    n = round(p_n * m)\n",
    "    num_children_needed = round(n * p_crossover)\n",
    "    num_mutation_needed = n - num_children_needed\n",
    "    sorted_ruleset = sorted(ruleset, key=lambda x: x.fitness, reverse = True)\n",
    "    crossover_without_mutation = ruleset[:m-n]\n",
    "    crossover_with_mutation = []\n",
    "    offspring = []\n",
    "\n",
    "    for i in range(num_children_needed):\n",
    "        p1, p2 = select_parents(sorted_ruleset)\n",
    "        offspring.append(p1.reproduce(p2))\n",
    "    \n",
    "    for j in range(num_mutation_needed):\n",
    "        candidate = select_one(sorted_ruleset)\n",
    "        candidate.mutate()\n",
    "        crossover_with_mutation.append(candidate)\n",
    "\n",
    "    return crossover_without_mutation + offspring + crossover_with_mutation\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953cbbb",
   "metadata": {},
   "source": [
    "Prepare the environment and generate a given number of rulesets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "284f61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "list_to_return = []\n",
    "\n",
    "ruleset = generate_ruleset(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1516711d",
   "metadata": {},
   "source": [
    "Running for 3 generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc0c31c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m     16\u001b[0m     mapped_observation \u001b[39m=\u001b[39m mapping_observation_to_1D(observation, \u001b[39m10\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action(mapped_observation, rule))\n\u001b[1;32m     18\u001b[0m     score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[1;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m terminated \u001b[39mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/study/lib/python3.10/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m     \u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/study/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/study/lib/python3.10/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/study/lib/python3.10/site-packages/gym/envs/classic_control/cartpole.py:187\u001b[0m, in \u001b[0;36mCartPoleEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    184\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m    188\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32), reward, terminated, \u001b[39mFalse\u001b[39;00m, {}\n",
      "File \u001b[0;32m/opt/miniconda3/envs/study/lib/python3.10/site-packages/gym/envs/classic_control/cartpole.py:295\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m gfxdraw\u001b[39m.\u001b[39mhline(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf, \u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscreen_width, carty, (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[1;32m    294\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mflip(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf, \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 295\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscreen\u001b[39m.\u001b[39;49mblit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msurf, (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m))\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    297\u001b[0m     pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mpump()\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "\n",
    "gen = 3\n",
    "scoreboard = pd.DataFrame()\n",
    "for i in range(gen):\n",
    "    rule_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for rule in ruleset:\n",
    "        score = 0\n",
    "        maxscore = 0\n",
    "\n",
    "\n",
    "        for episode in range(10):\n",
    "            mapped_observation = mapping_observation_to_1D(observation, 10)\n",
    "            observation, reward, terminated, truncated, info = env.step(action(mapped_observation, rule))\n",
    "            score += reward\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                observation, info = env.reset()\n",
    "                if score > maxscore:\n",
    "                    maxscore = score \n",
    "                score = 0\n",
    "\n",
    "        rule_list.append(rule.geno)\n",
    "        score_list.append(maxscore)\n",
    "        rule.update_fitness(maxscore)\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    df = pd.DataFrame({'Rules':rule_list, 'Fitness': score_list})\n",
    "    # df = df.astype(str)\n",
    "    df.to_csv(f'results_generation_{i}.csv', index=False, header=False, sep=\";\")\n",
    "\n",
    "    scoreboard[f'Generation_{i}'] = score_list\n",
    "\n",
    "    ruleset = evovle(ruleset,0.5, 0.8)\n",
    "\n",
    "scoreboard.to_csv(f'scores_after_{i}_generations.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "29d06b973d1ddb34db3279b24f9b5152402e688db937648b736e855ec4de60c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
